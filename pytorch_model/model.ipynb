{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pytorch_transform import Transformer\n",
    "from pytorch_dataset_tupple_generator import Dataset_Tuple_Loader\n",
    "from torch.utils import data\n",
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transformation_param = {\n",
    "    'nn_input_image_shape': (100, 100),\n",
    "    'crop_pixel': (20, 20),\n",
    "    'rotation_angles' :[25,15,12,0,-12,-15,-25],\n",
    "    'rotaion_angle_probabilities' :[0.01,0.02,0.12,0.70,0.12,0.02,0.01],\n",
    "    'flip_hor_ver_probabilities' :(0.4, 0.07),\n",
    "    'gaussian_filter_probability' : 0.04,\n",
    "    'unsharp_mask_filter_probability' : 0.04\n",
    "}\n",
    "dataloader_param = {'batch_size': 2,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '/home/abjb/workspace/facedetection_models/pytorch_retrain/sam.csv'\n",
    "image_root = '/home/abjb/workspace/facedetection_models/pytorch_retrain/samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abjb/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \n",
      "/home/abjb/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for x,y in generator:\n",
    "    imsave(name = '/home/abjb/workspace/facedetection_models/pytorch_retrain/dataloader_testing/'+str(y[0])+'.jpeg' , arr =  x[0])\n",
    "    imsave(name = '/home/abjb/workspace/facedetection_models/pytorch_retrain/dataloader_testing/'+str(y[1])+'.jpeg' , arr = x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, model_dict,data_dict):\n",
    "        self.model = model_dict['model']\n",
    "        self.image_transform_param = model_dict['image_transormations']\n",
    "        self.model_hyperparam = model_dict['model_hyperparam']\n",
    "        self.dataset = data_dict\n",
    "        self.model_metric = model_dict['metric']\n",
    "        self.dataset_generator_param ={\n",
    "            'batch_size' : self.model_hyperparam['batch_size'],\n",
    "            'shuffle' : True,\n",
    "            'num_workers' : self.model_hyperparam['generator_num_worker']\n",
    "        }\n",
    "        img_source = data_dict['source']\n",
    "        img_address_root = data_dict['image_root_address']\n",
    "        label_address = data_dict['label_address']\n",
    "        \n",
    "        # Creating image transformation function\n",
    "        transforms = Transformer(self.image_transform_param).transforms()        \n",
    "        # Creating Dataset instance and passing root of image ,csv(labels) and transformations criterion\n",
    "        set_loader = Dataset_Tuple_Loader(img_source=img_source,\n",
    "                                          img_root=image_address_root,\n",
    "                                          csv_label_address=label_address,\n",
    "                                          transforms=transforms)\n",
    "        # Creating Generator for parallelising set_loader\n",
    "        self.generator = data.DataLoader(set_loader, **self.dataset_generator_param)\n",
    "    \n",
    "    def __call__(self)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
